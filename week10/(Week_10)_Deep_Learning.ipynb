{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "(Week_10)_Deep_Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq1t9bGsDTvi"
      },
      "source": [
        "Do not delete this cell. It defines custom LaTeX commands.\n",
        "$$\n",
        "\\newcommand{\\xb}{\\boldsymbol{x}}\n",
        "\\newcommand{\\wb}{\\boldsymbol{w}}\n",
        "\\newcommand{\\pb}{\\boldsymbol{p}}\n",
        "\\newcommand{\\1}{\\mathbb{1}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfyI_9zZPwsa"
      },
      "source": [
        "# **Convolutions and Convolutional Neural Networks**\n",
        "\n",
        "**Here you'll experiment with convolutions, on CPUs and GPUs, and with convolutional neural networks.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKqJ2q6XalPc"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage.data\n",
        "import skimage.color\n",
        "import scipy.misc\n",
        "import scipy.signal\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from matplotlib import rcParams\n",
        "rcParams['axes.grid'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYyOOyiqAZHB"
      },
      "source": [
        "## **Convolutions with SciPy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYevMovGlZwu"
      },
      "source": [
        "**Let's start by loading a simple image of coffee using scikit-image, converting it to grayscale, and viewing it.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngJRcz3GkfL2"
      },
      "source": [
        "**You will likely get an error when you run the following line of code. This issue has to do with Google's Colaboratory environment. To fix it, just restart the runtime (`Runtime -> Restart Runtime`) and then run all of the code above again (`Runtime -> Run Before`).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bN1tD8sTHRf"
      },
      "source": [
        "image = skimage.color.rgb2gray(skimage.data.coffee()).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FLTgKhelnaL"
      },
      "source": [
        "**In the following cell, write code to print this image's `dtype`, `shape`, and minimum and maximum values.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5nASIC_LMkP"
      },
      "source": [
        "# TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlcKAdcbmSzI"
      },
      "source": [
        "**Let's view the image:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TThQrKHHM45T"
      },
      "source": [
        "plt.imshow(image)\n",
        "plt.axis('image')\n",
        "plt.set_cmap('gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ccw6QXmWMd"
      },
      "source": [
        "**Now let's create a 15 x 15 averaging filter:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--jy1G76OTF5"
      },
      "source": [
        "kernel_shape = [15, 15]\n",
        "kernel = np.ones(kernel_shape, dtype=np.float32) / np.prod(kernel_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX3kZ9AinMCU"
      },
      "source": [
        "**In the following Markdown cell, answer: Why are we dividing by the product of `kernel_shape`'s elements here?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvZpThvrnMKf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIqhxZdkh6xU"
      },
      "source": [
        "**We can then apply the kernel to our image.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTIOmFsuPC5w"
      },
      "source": [
        "image_smoothed = scipy.signal.convolve2d(image, kernel, mode='same')\n",
        "kernel.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB3ErkbKnyKQ"
      },
      "source": [
        "**Copy the previous line of code to the cell below and use IPython's `%timeit` magic to see how long this convolution takes.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoX25pDl3MJg"
      },
      "source": [
        "%timeit # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2hFzJI9oYcF"
      },
      "source": [
        "**In the following Markdown cell, answer: Approximately how many milliseconds does it take for this 2-D convolution to complete?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwZDKecVom2t"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7KhNWmWWKcq"
      },
      "source": [
        "**In the following Markdown cell, answer: We specified `mode='same'` so that the output image has the same size as the input image. If we instead retained only *valid* outputs – those computed using only values within `image` and `kernel` – what would the shape of the output image be?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx1hvRUcWKl-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbiai9eppSvu"
      },
      "source": [
        "**In the following Markdown cell, answer: Expanding on the previous question, suppose you convolve an image of shape `[HEIGHT, WIDTH]` with a kernel of smaller shape `[K_HEIGHT, K_WIDTH]`, where `K_HEIGHT` and `K_WIDTH` are odd. Then what is the shape of the output of the convolution if only *valid* outputs are retained?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF7e6hfHpTE2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL_H572jqzTn"
      },
      "source": [
        "**Let's visualize the output of this convolution.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SutR-ubdQeXA"
      },
      "source": [
        "plt.imshow(image_smoothed)\n",
        "plt.axis('image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orMqjBbWXir-"
      },
      "source": [
        "**In the following Markdown cell, answer: Why is there an artificial dark border surrounding this output image (which is not present in the original image above)?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooDTTTcrXii6"
      },
      "source": [
        "**This is the result of using `mode='same'`. Here the original image is effectively padded with 0s so that a 'valid' convolution yields an output that has the same shape as the input image. These 0s are darker than the actual image, so when we include them in our averages, we see this artificial border.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIiqaW_pAiKw"
      },
      "source": [
        "## **Convolutions with PyTorch (CPU only)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTOElGcqrZYs"
      },
      "source": [
        "image_ = Variable(torch.from_numpy(image))\n",
        "kernel_ = Variable(torch.from_numpy(kernel))\n",
        "kernel_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov3pjWtgzebj"
      },
      "source": [
        "**In the following Markdown cell, answer: Look up the documentation for `torch.nn.functional.conv2d`. What shape does it expect for `input`, and what shape does it expect for `weight`? (Note that in our usage, the argument `groups` is 1.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-R_nV35zfQL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MLTms1VreNg"
      },
      "source": [
        "**In the following cell, write code to reshape `image_` and `kernel_` so that they can be passed to `torch.nn.functional.conv2d`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRPJUmBYzaQM"
      },
      "source": [
        "# TODO\n",
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uWadNsJ-2KN"
      },
      "source": [
        "**Now let's define appropriate padding (so that our output image again remains the same size at the input image) and use PyTorch's `conv2d` to perform the convolution.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya160ByEzsK7"
      },
      "source": [
        "padding = (kernel_shape[0] // 2, kernel_shape[1] // 2)\n",
        "image_smoothed_ = F.conv2d(image_, kernel_, padding=padding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIds1cY5z6Gf"
      },
      "source": [
        "**Copy the previous cell's code to the cell below and use IPython's `%timeit` magic to see how long this convolution takes in PyTorch.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2bN5CIS3gAj"
      },
      "source": [
        "%timeit # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_5tdEwV0MLS"
      },
      "source": [
        "**In the following Markdown cell, answer: Approximately how many milliseconds does it take for this 2-D convolution to complete?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpTNVJgp1ffC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX5A3fgx1h2N"
      },
      "source": [
        "**In the following Markdown cell, answer: How much faster is PyTorch's implementation in comparison to SciPy's? (To answer this, just compute the ratio $T_\\text{SciPy}$ / $T_\\text{PyTorch}$.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW68UJ8g4RhQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzBbittO-v8g"
      },
      "source": [
        "**In the following Markdown cell, answer: Can you guess why PyTorch is faster here? (It's fine if you aren't sure; if so, just leave it blank.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ79UzHs-wcc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI40jGBT6BRI"
      },
      "source": [
        "**Again let's visualize the output to make sure it's what we expect.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqCZkiFE6BrU"
      },
      "source": [
        "plt.imshow(image_smoothed_.data.numpy().squeeze())\n",
        "plt.axis('image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCmTo8KjAoPf"
      },
      "source": [
        "## **Convolutions with PyTorch (GPU)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB2WnTAS_SHz"
      },
      "source": [
        "**Now let's move on to using CUDA in PyTorch, to leverage GPUs. (If you haven't heard of CUDA, take a quick look at https://en.wikipedia.org/wiki/CUDA.)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh91ifRi5nC6"
      },
      "source": [
        "assert torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ipNrsWY5pkf"
      },
      "source": [
        "**If the above `assert` fails, hit `Edit -> Notebook Settings` and make sure GPU acceleration is enabled.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo7xGL6qiN-7"
      },
      "source": [
        "**We can then move our images on the GPU and apply the smoothing operation as a convolution.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMS22ug04R4o"
      },
      "source": [
        "image_ = image_.cuda()\n",
        "kernel_ = kernel_.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL4HJDxo6PZb"
      },
      "source": [
        "image_smoothed_ = F.conv2d(image_, kernel_, padding=padding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3iQClTT6WUp"
      },
      "source": [
        "**Copy the above code to the cell below and use IPython's `%timeit` magic to see how long this convolution takes in PyTorch using our GPU.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoKZ8FKf4SAI"
      },
      "source": [
        "%timeit # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II2acbTq6oPz"
      },
      "source": [
        "**In the following Markdown cell, answer: Approximately how many milliseconds does it take for this 2-D convolution to complete?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT5ggM0N6oP0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRlo93K26oP1"
      },
      "source": [
        "**In the following Markdown cell, answer: How much faster is PyTorch's GPU implementation in comparison to SciPy's CPU implementation? And how much faster is PyTorch's GPU implementation than PyTorch's CPU implementation? (Answer these as done above, as $T_\\text{PyTorch GPU}$ / $T_\\text{SciPy}$ and $T_\\text{PyTorch GPU}$ / $T_\\text{PyTorch CPU}$.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT2y436k6oP2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAECxm7EBfL7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gHuLtMV_oUS"
      },
      "source": [
        "**Now let's go on to convolve an RGB image (height x width x 3) with a kernel that's 15 x 15 x 3.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCdPdOSw4SQ2"
      },
      "source": [
        "image = skimage.data.coffee().astype(np.float32)\n",
        "image /= image.max()\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BemKmnywCxeV"
      },
      "source": [
        "**In the following cell, write code to print this image's `dtype`, `shape`, and minimum and maximum values.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I45cn5QFCxd8"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPj0xSAcgzyj"
      },
      "source": [
        "**Let's create a 3D kernel for convolution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n_fur99pBom"
      },
      "source": [
        "kernel_shape = [15, 15, 3]\n",
        "kernel = np.ones(kernel_shape, dtype=np.float32) / np.prod(kernel_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFa9yZD9g_aQ"
      },
      "source": [
        "**Turn the image and kernel into tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAIFE6zJrY7z"
      },
      "source": [
        "image_ = Variable(torch.from_numpy(image).cuda())\n",
        "kernel_ = Variable(torch.from_numpy(kernel).cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98mB1mSEuTbc"
      },
      "source": [
        "**In the following cell, write code to permute and reshape axes so that `image_` and `kernel_` have the shapes expected by `torch.nn.functional.conv2d`. (You can use `permute` and `unsqueeze` here.)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fEM8M5CrYyZ"
      },
      "source": [
        "# TODO\n",
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAe_eTNSvHF9"
      },
      "source": [
        "**After the `permute`, we need to make our Variables contiguous. (`permute` changes the order in which we view memory, but avoids rearranging the order explicitly. Thus we need to explicitly reorder the memory so that future manipulations can operate as expected.)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp8b_tjUvyGm"
      },
      "source": [
        "image_ = image_.contiguous()\n",
        "kernel_ = kernel_.contiguous()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc0sQ3gjrYqr"
      },
      "source": [
        "**In the following cell, write code to print the shape of `image_` and `kernel_`, and confirm they're what you expect.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzDFGF96uAkl"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4sWen8IiYgr"
      },
      "source": [
        "**Convolve the image again with the kernel.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FsijrQeuHqc"
      },
      "source": [
        "output_ = F.conv2d(image_, kernel_, padding=padding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhP8I6P4v3Wd"
      },
      "source": [
        "**In the following cell, write code to print the `type` and `shape` of `output_.data`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5GcnUTSv30g"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09nbb-PNwjSA"
      },
      "source": [
        "**In the following Markdown cell, answer: Why does the output have 1 output channel instead of 3?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxZ4p0TLwjpX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjZeHWkl_98I"
      },
      "source": [
        "**Finally, let's visualize the result.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-quIcn8aAAct"
      },
      "source": [
        "plt.imshow(output_.data.cpu().numpy().squeeze())\n",
        "plt.axis('image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv0uKzQZA4HW"
      },
      "source": [
        "## **MNIST Classification with Extremely Simple CNNs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_ETS9yliqKB"
      },
      "source": [
        "**We can first setup the necessary environment and constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5U9S21LKoH"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "from pathlib import Path\n",
        "HOME = Path.home()\n",
        "MNIST_PATH = HOME / 'data' / 'mnist'\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "CHANNELS = 1\n",
        "HEIGHT = 28\n",
        "WIDTH = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMIfBVEGiydX"
      },
      "source": [
        "**We're going to load the official train set and never touch the true test set in these experiments, which consists of 10,000 separate examples. We'll instead split our training set into a set for training and a set for validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThF_mw3iasJ2"
      },
      "source": [
        "official_mnist_train = torchvision.datasets.MNIST(str(MNIST_PATH), train=True, download=True)\n",
        "official_train_images = official_mnist_train.train_data.numpy().astype(np.float32)\n",
        "official_train_labels = official_mnist_train.train_labels.numpy().astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdhHhkpFxTUV"
      },
      "source": [
        "print(official_train_images.shape)\n",
        "print(official_train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yVKLOn8_EMD"
      },
      "source": [
        "**Let's view a few examples:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJxxlEjhcpW9"
      },
      "source": [
        "example_images = np.concatenate(official_train_images[:10], axis=1)\n",
        "example_labels = official_train_labels[:10]\n",
        "print(example_labels)\n",
        "plt.imshow(example_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toe9gJyK_LBO"
      },
      "source": [
        "**Here we'll split our training set into 55000 for training and the rest for validation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60IytczeT22"
      },
      "source": [
        "train_images, val_images = np.split(official_train_images, [55000])\n",
        "train_labels, val_labels = np.split(official_train_labels, [55000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uReKYU4y5k0"
      },
      "source": [
        "print(train_images.shape, train_labels.shape)\n",
        "print(val_images.shape, val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocXrRfsX_VwM"
      },
      "source": [
        "**And we'll normalize our data in one of the simplest ways possible: centering and scaling on an image-by-image basis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJsU5u9WhBzN"
      },
      "source": [
        "def normalize_stats_image_by_image(images):\n",
        "  mean = images.mean(axis=(1,2), keepdims=True)\n",
        "  stdev = images.std(axis=(1,2), keepdims=True)\n",
        "  return (images - mean) / stdev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL9XyAMYk8qs"
      },
      "source": [
        "train_images = normalize_stats_image_by_image(train_images)\n",
        "val_images = normalize_stats_image_by_image(val_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SuhrgjUi8xo"
      },
      "source": [
        "**We can print the mean and stddev to make sure that normalization is done correctly.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgIXQ0QO0NUy"
      },
      "source": [
        "print(train_images[:3].mean(axis=(1, 2)))\n",
        "print(train_images[:3].std(axis=(1, 2)))\n",
        "print(val_images[:3].mean(axis=(1, 2)))\n",
        "print(val_images[:3].std(axis=(1, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmWbExBjHPc1"
      },
      "source": [
        "**We'll define a function to return a batch of examples. Since we assume GPU is available, we also move these images to the GPU.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV-22bUNDRpO"
      },
      "source": [
        "def batch(batch_size, training=True):\n",
        "  \"\"\"Create a batch of examples.\n",
        "  \n",
        "  This creates a batch of input images and a batch of corresponding\n",
        "  ground-truth labels. We assume CUDA is available (with a GPU).\n",
        "  \n",
        "  Args:\n",
        "    batch_size: An integer.\n",
        "    training: A boolean. If True, grab examples from the training\n",
        "      set; otherwise, grab them from the validation set.\n",
        "  \n",
        "  Returns:\n",
        "    A tuple,\n",
        "    input_batch: A Variable of floats with shape\n",
        "      [batch_size, 1, height, width]\n",
        "    label_batch: A Variable of ints with shape\n",
        "      [batch_size].\n",
        "  \"\"\"\n",
        "  if training:\n",
        "    random_ind = np.random.choice(train_images.shape[0], size=batch_size, replace=False)\n",
        "    input_batch = train_images[random_ind]\n",
        "    label_batch = train_labels[random_ind]\n",
        "  else:\n",
        "    input_batch = val_images[:batch_size]\n",
        "    label_batch = val_labels[:batch_size]\n",
        "  \n",
        "  input_batch = input_batch[:, np.newaxis, :, :]\n",
        "  \n",
        "  volatile = not training\n",
        "  input_batch = Variable(torch.from_numpy(input_batch).cuda(), volatile=volatile)\n",
        "  label_batch = Variable(torch.from_numpy(label_batch).cuda(), volatile=volatile)\n",
        "  \n",
        "  return input_batch, label_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUqtXLFAE0kH"
      },
      "source": [
        "**Below, you will define a `SimpleCNN` with some significant restrictions on the model class:**\n",
        "\n",
        "**(1) Input to conv_final needs to be a single pixel (see comments where it is defined).** \n",
        "\n",
        "**(2) Only Convolutions and ReLUs can be used. In other words, do not use max pooling, do not use dropout, etc.**\n",
        "\n",
        "**The purpose of this is to (1) gain competency with the basic settings for convolutions and (2) develop a practical sense for how important these basic settings are.**\n",
        "\n",
        "**Target: Try to achieve better than 2% error.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-HmEaKsqYZT"
      },
      "source": [
        "**Hint 1: You can use the `stride` argument in the convolutions.**\n",
        "\n",
        "**Hint 2: This can easily be achieved in well under 5000 iterations using the same optimizer settings as below (Adam with a learning rate of 0.001).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVZjEc5FGzDn"
      },
      "source": [
        "class SimpleCNN(torch.nn.Module):\n",
        "  \"\"\"A simple convolutional network.\n",
        "  \n",
        "  Map from inputs with shape [batch_size, 1, height, width] to\n",
        "  outputs with shape [batch_size, 1].\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=7, padding=7//2) # feel free to change these parameters.\n",
        "    # TODO\n",
        "    # (You may also need to modify conv_final.)\n",
        "    # self.conv2 = \n",
        "    # self.conv3 = \n",
        "    # self.conv4 = \n",
        "    # self.conv5 = \n",
        "    \n",
        "    # Here the input to conv_final should be a single pixel, as can be obtained\n",
        "    # by pooling spatially over all pixels. The goal of conv_final is to map\n",
        "    # from some number of channels to 10, one for each possible class.\n",
        "    \n",
        "    # Here, in_channel = 128, but feel free to change that. All other parameters for conv_final should remain the same.\n",
        "    self.conv_final = torch.nn.Conv2d(128, 10, kernel_size=1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    # TODO\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub3vnKdME6J3"
      },
      "source": [
        "**And instantiate our model... notice again that we assume CUDA is available, and that moving all parameters to the GPU is as simple as running `model.cuda()`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhK3Dyy-LoLW"
      },
      "source": [
        "model = SimpleCNN()\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El2xSj-yLoVU"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTXoFOVOrJAD"
      },
      "source": [
        "**Helper function that performs the forward pass, backpropagation, and then gradient update steps for a single batch.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxMEN0hsxMbm"
      },
      "source": [
        "def train_step(batch_size=128):\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  input_batch, label_batch = batch(batch_size, training=True)\n",
        "  output_batch = model(input_batch)\n",
        "  \n",
        "  loss = F.cross_entropy(output_batch, label_batch)\n",
        "  _, pred_batch = torch.max(output_batch, dim=1)\n",
        "  error_rate = 1.0 - (pred_batch == label_batch).float().mean()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  \n",
        "  optimizer.step()\n",
        "  \n",
        "  return loss.data, error_rate.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gom-w-EnrOLY"
      },
      "source": [
        "**Evaluation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7JygaaR9KkO"
      },
      "source": [
        "def val():\n",
        "  \n",
        "  model.eval()\n",
        "  input_batch, label_batch = batch(val_images.shape[0], training=False)\n",
        "  output_batch = model(input_batch)\n",
        "\n",
        "  loss = F.cross_entropy(output_batch, label_batch)\n",
        "  _, pred_batch = torch.max(output_batch, dim=1)\n",
        "  error_rate = 1.0 - (pred_batch == label_batch).float().mean()\n",
        "  \n",
        "  return loss.data, error_rate.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_LCeeO92kLB"
      },
      "source": [
        "**Finally, let's train, and also plot loss and error rate as a function of iteration.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKSCshLB87yc"
      },
      "source": [
        "# Let's make sure we always start from scratch (that is,\n",
        "# without starting from parameters from a previous run).\n",
        "for module in model.children():\n",
        "  module.reset_parameters()\n",
        "\n",
        "info = []\n",
        "fig, ax = plt.subplots(2, 1, sharex=True)\n",
        "num_steps = 5000\n",
        "num_steps_per_val = 50\n",
        "best_val_err = 1.0\n",
        "for step in range(num_steps):\n",
        "  train_loss, train_err = train_step()\n",
        "  if step % num_steps_per_val == 0:\n",
        "    val_loss, val_err = val()\n",
        "    if val_err < best_val_err:\n",
        "      best_val_err = val_err\n",
        "      print('Step {:5d}: Obtained a best validation error of {:.3f}.'.format(step, best_val_err))\n",
        "    info.append([step, train_loss, val_loss, train_err, val_err])\n",
        "    x, y11, y12, y21, y22 = zip(*info)\n",
        "    ax[0].plot(x, y11, x, y12)\n",
        "    ax[0].legend(['Train loss', 'Val loss'])\n",
        "    ax[1].plot(x, y21, x, y22)\n",
        "    ax[1].legend(['Train err', 'Val err'])\n",
        "    ax[1].set_ylim([0.0, 0.25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHVDYeHH4t3c"
      },
      "source": [
        ""
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPenj5Yxj0mO"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCp4KNhvkakN"
   },
   "source": [
    "### Read this First\n",
    "\n",
    "#### Remember that `tab` is is useful for autocompletion.\n",
    "\n",
    "#### Remember that `shift + tab` is useful for rapidly obtaining usage + documentation.\n",
    "\n",
    "#### If you want to plot grayscale images, use the parameter cmap='gray' when plt.imshow\n",
    "\n",
    "#### If you want the figures to be bigger, you can call plt.figure(figsize=(12, 8)) before calling plt.imshow (feel free to modify the values in figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WuMgBKgwklAm"
   },
   "source": [
    "### **Edge Detection 1D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuhmmowDlg1d"
   },
   "source": [
    "**In class we learned a lot about edge detection and the various techniques that enable us to perform edge detection. In this notebook we'll run through a few examples to get you more familiarized with edge detection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4f2cYe7mfyE"
   },
   "source": [
    "**Edges are simply rapid changes in image intensity within a smalll region, and despite the seemingly obvious description, there are a variety of types of edges. Below are some of these edges in 1D.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFB5m3TemzVu"
   },
   "outputs": [],
   "source": [
    "edge_step_1 = np.array([0, 0, 0, 0, 0, 5, 5, 5, 5, 5])\n",
    "edge_step_2 = np.array([0, 0.5, 1, 1.5, 2, 9, 8.5, 8.0, 7.5, 7.0])\n",
    "edge_step_3 = np.array([0, 0.5, 1, 1.5, 2, 7.8, 8.4, 8.8, 9.0, 9.0])\n",
    "edge_line_1 = np.array([0, 0, 0, 0, 7, 7, 0, 0, 0, 0])\n",
    "edge_line_2 = np.array([6, 5, 4, 3, 8, 8, 3, 2, 1, 0])\n",
    "edge_roof_1 = np.array([3, 4, 5, 6, 7, 8, 6.5, 5, 3.5, 2])\n",
    "edge_real_1 = np.array([0, 1, 1, 0, 1, 8, 7, 9, 7, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htdGFP5mnhdi"
   },
   "source": [
    "**Seems pretty hard to visualize with just numbers (at least for me). Plot the edge_step edges in one graph, the edge_line edges in one graph, and the edge_roof and edge_real edges in one graph.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmXa8hprn22b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3ZNvHZWpQyP"
   },
   "source": [
    "**We see that there are many different types of edges, and that real edges are often noisy, as seen in edge_real_1.**\n",
    "\n",
    "**So let's begin to explore how we are able to find the exact location of the edge within these 1D arrays.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4n16gYxPpxbS"
   },
   "source": [
    "**Write a function below that computes the derivative of the 1D array. That is, it computes the difference between the current value and the next value for each value in the array. We won't worry too much about boundary conditions right now, so we'll just have the derivative array be one shorter than the input edge array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fVXBOxFqFx0"
   },
   "outputs": [],
   "source": [
    "def derivative_1d(edge):\n",
    "  \"\"\" Finds the derivative of the 1D array.\n",
    "      The derivative at position i is simply (edge[i + 1] - edge[i])\n",
    "      Args: \n",
    "          edge: A 1D numpy array with length [n]\n",
    "      Returns:\n",
    "          derivative: A 1D numpy array with length [n - 1]\n",
    "  \"\"\"\n",
    "\n",
    "  # Finish the function\n",
    "\n",
    "\n",
    "  return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oa518paIqEz6"
   },
   "source": [
    "**Test your function out by running it with the edge_real_1 above and another edge array of your choice. For each edge, plot both the edge and its derivative on the same graph (which means you should be plotting two graphs here). When plotting, shift your derivative plot by 0.5 units so that each plotted value appears between the two elements that was used to compute it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEElwQPTraL8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDXh2P8otkFD"
   },
   "source": [
    "**From the plot of the edge_real, we see that there are multiple peaks, but the largest peak there corresponds to what we consider as the edge.**\n",
    "\n",
    "**Within the function you wrote above, you probably (hopefully you did?) either looped through each element to take the difference with the next value, or did some list subtraction. Either way, we can actually do this via convolutions! Convolutions are useful when we want to apply the same operation to each element by applying some relationship with neighbouring cells, which is exactly what the derivative is doing!**\n",
    "\n",
    "**Create a 2 element 1D kernel [1, -1]. Convolve this with the same two edges that you plotted just now (use mode='valid' to get the same output dimensions are your function). This time plot the convolution result you got here with the derivative you found using your function (again, have a different plot for each of the edges)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4wP5f2Yu6dh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKn8CQE2vgy1"
   },
   "source": [
    "**They should be exactly the same! Recall that for convolutions, there's first a flip and then a shift. The flip means the kernel becomes [-1, 1]. Shifting over each value then results in edge[i + 1] - edge[i]. Now you've seen convolutions being used for edge detection in 1D, we can now move to 2D images!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3UVs16Kxvl_4"
   },
   "source": [
    "### **Edge Detection 2D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDyiWDXUvp9k"
   },
   "source": [
    "**Now let's see what we can do with images. First, load 'cv_edge_detect.jpg'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NejYnpU_lhMS"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "original_image = cv2.imread('cv_edge_detect.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arYnRvFIv-rn"
   },
   "source": [
    "**We saw just now how we could use a kernel and convolution to find the edges in 1D arrays. Let's do the same thing with images! This time, create a 2D kernel of size (1, 3) that is [-1, 0, 1] and convolve that with the image loaded above. Display the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fr98QK1U0DTg"
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YG39Tpq01T3q"
   },
   "source": [
    "**What does this seem to be doing? Why can't you see the bottom edge of the mascot's left shoe?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1C5DTgCo1nCK"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_H11B5U1nqu"
   },
   "source": [
    "**Now, create a 2D kernel of size (3, 1) that is [-1, 0, 1] and convolve that with the original image. Display the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjDxErYq1MdY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVXLfkSK1zJ6"
   },
   "source": [
    "**What does this do that's different? What about the convolution kernels make the images look different?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5aBfPB015_B"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUCi64G216sB"
   },
   "source": [
    "**Using these kernels, what we're doing is essentially taking the gradient between pixels in the x, and in the y direction respectively. Hence in each of the images after convolution, each pixel value is the gradient in either the x direction or the y direction.**\n",
    "\n",
    "**Besides taking the simple derivative between the two neighbouring pixels, we can also try and compute the derivative by taking into account the pixel values of more surrounding pixels, and taking the derivative across those pixels. We can do this using the sobel filters, as you've probably seen in class. Use cv2 to apply the sobel filter of size 7 in the x, and also in the y direction separately, and display both images.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9inkjKnX7lGU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2X_505wz8JkR"
   },
   "source": [
    "**You'll notice that the sobel operator makes the resulting gradient image slightly blurry, since it incorporates a bit of gaussian smoothening with it. Why do we want to consider a larger area when computing the gradient?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89BVYBAz-4pN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DipAWern8y8c"
   },
   "source": [
    "**It's nice being able to find the gradient in the x and in the y directions separately, but it's not nice always having to look through both images in order to find all of the edges. Also, some of the diagonal edges show up faintly in both the horizonal and vertical gradient images, as its gradient contribution is split across the two images.**\n",
    "\n",
    "**Hence we need some way of combining these gradients in different directions, such that identical edges oriented differently will have the same representation in one single image.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5fK7j_G9pUl"
   },
   "source": [
    "**This brings us to the concept of gradient magnitude, which in essence, is the strength of the edge at that particular pixel. When computing this, we don't care about the orientation of the edge - a strong edge in the x direction should have the same magnitude if that edge is oriented in any other direction.**\n",
    "\n",
    "**Write a function below that does exactly this. Given an image and a filter size, it uses the sobel operator (sigma = filter size) to find the gradients in the x, and in the y directions, and then computes the gradient magnitude at each pixel and returns the resulting gradient magnitude map.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_bb79r0_z5w"
   },
   "outputs": [],
   "source": [
    "def gradient_magnitude(image, filter_size):\n",
    "  \"\"\" Finds the gradient magnitude map of the image.\n",
    "      The equation for gradient magnitude should be in slide 12 of lecture 5 (assuming that I have the same slides as you)\n",
    "      Args: \n",
    "          image: A 2D grayscaled image\n",
    "          filter_size: An int representing the size of the sobel filters\n",
    "      Returns:\n",
    "          grad_mag: A 2D gradient magnitude map\n",
    "  \"\"\"\n",
    "\n",
    "  # Finish the function\n",
    "\n",
    "  return grad_mag\n",
    "\n",
    "gradient_image = gradient_magnitude(original_image, 5)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(gradient_image, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7cF4mXosAot7"
   },
   "source": [
    "**That's great! Jay's edges and curves should now be very clear in this image. But notice a problem - there's a lot of textures on Jay, which show up as fainter edges in our gradient magnitude map. We don't really count these textures as an edge, so we want to remove them. Since they appear weaker in magnitude than true edges, we can remove them via thresholding!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6zsDC2LC0nQ"
   },
   "source": [
    "**To start, let's use a simple threshold - set all pixels of gradient_image with a gradient magnitude greater than 3000 to 255, and everything else to 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOc6aBF0C7yj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96grg9ANEjnO"
   },
   "source": [
    "**It looks a lot better now, with the majority of the fine details removed. However, there's still quite a lot of noise in the image from the texture. There's a method that we can use to remove some of this noise on Jay, and we've already applied it to \"j\" previously... Once you figure it out, use a 2x2 kernel of ones. Display the result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCeglIyeEx7P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvMz1KA6JEp_"
   },
   "source": [
    "**We see that a lot of the noise has been removed! But Jay has lost some of his edges along the way, hence this isn't the best way to do it.**\n",
    "\n",
    "**Another thresholding method that works better is hysteresis based. This method has two thresholds. Anything below the lower threshold is not an edge, and everything above the upper threshold is an edge. Anything in between the two thresholds is only an edge if a neighbouring cell is an edge.**\n",
    "\n",
    "**I was going to run you through an implementation of it, but this may or may not be in your homework? So here's a skimage implementation that does this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECG28PaJH7kO"
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "gradient_image = gradient_magnitude(original_image, 5)\n",
    "hyst = filters.apply_hysteresis_threshold(gradient_image, 3300, 3600)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(hyst, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_NKbluQPJSl"
   },
   "source": [
    "### **Edge Detection Kernels in 2D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrHYKz9QPMXt"
   },
   "source": [
    "**Recall earlier when we talked about how the Sobel operator has some smoothening inherently within it? Let's explore that briefly using the gradient_magnitude function that you wrote earlier. Display the results of running gradient_magnitude on original_image with a filter size of 1, and another using a filter size of 9.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-iMkirzP70l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9VVbAfFL17u1"
   },
   "source": [
    "**What are the differences between these two?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADmVqfJG19fX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOXkIeEC1-An"
   },
   "source": [
    "**We can also do this using the derivative of the gaussian filter directly, instead of using the sobel filter, using Scipy's implementation of gaussian filter. Use scipy's gaussian_filter to apply the derivative of the gaussian on our original image with a sigma=2 in the x direction, and then in the y direction separately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dt6IyyEq1_mZ"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJuMu1xp2CPv"
   },
   "source": [
    "**Repeat what you did above, this time applying the derivative of the gaussian in both directions simulataneously.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjHUqd4H2EfX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rbh9mtrMR-QY"
   },
   "source": [
    "**Play around with the sigma parameter. What does increasing/decreasing sigma do to the resultant image?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F-xs8Fo6ScK2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVrcjeRb12ET"
   },
   "source": [
    "**Why do we need to apply smoothening before taking the derivative to find the edges?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9fh4Fx313bx"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DHJJv0JESc1S"
   },
   "source": [
    "**Recall that convolution operations are associative. Since both the gaussian smoothening and gradient operator are convolutions acting on the image, we see that we can convolve the gradient operator with the gaussian kernel, before convolving that resulting kernel with the image.**\n",
    "\n",
    "**There's another edge detection kernel that we can use - the laplacian operator. This basically takes the second derivative, meaning that the edges would be the zero crossings after convolution. Give it a try using cv2.Laplacian on our original_image and display the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XT439YB1R9kM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IegBJyV1mCY9"
   },
   "source": [
    "**If the image doesn't turn out very clear, make sure that the pixel value ranges are in a good range. If pixel values span from some negative number to some positive number, try to display the absolute value of the image instead.** \n",
    "\n",
    "**We see a lot of texture being picked up - let's smoothen the image first using scipy's gaussian filter with sigma=3, and then apply the same Laplacian filter again. Display the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ed7e3jXInlKP"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69ETYk1Qnl0e"
   },
   "source": [
    "**It's easy to see that this works as an edge detector, and unlike the derivatives of gaussians filter, the edges are very thin and precise. However, it's very sensitive - almost too sensitive, as the amount of texture detected is very high, even after smoothening.**\n",
    "\n",
    "**Good edge detection means good localization (laplacian) but robustness against noise (gaussian). Hence in order to combine the advantages, we can combine both. This is what the canny edge detector does.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_57_5OwpSj1"
   },
   "source": [
    "**In essence, the canny edge detector uses the sobel operator (derivative of gaussian approximation) to find the areas where an edge is. Because this uses the gaussian, it is more robust against noise, but is less accurate with regards to the exact position of the edge. Hence once the rough location of the edges are found, the laplacian of gaussians is run across the edge areas in order to better localize the edges. Since the laplacian is only run over areas identified by the Sobel operator as edges, it won't be detecting any noise as potential edges, which makes the Canny edge detector great at being robust against noise and great at localizing edges in the image.**\n",
    "\n",
    "**Let's give it a try! Use OpenCV's canny edge detector implementation on our original_image. Notice that the second and third parameters are the hysteresis thresholds for when thresholding is used to find the edges. Use 250 and 400, respectively, but feel free to play around with the values. Display the image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxAVS_1tqYpl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOFrfvK9k6C3"
   },
   "source": [
    "### **Hough Transform**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bg4vjeofv_Fh"
   },
   "source": [
    "**The hough transform is a very nice and relatively simple method of object recognition. It works pretty well for simple shapes (e.g. circles, lines, etc) and is robust to both noise and disconnected edges. We'll walk through a simple implementation of a hough transform for lines in this notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FPo6WqAwNzl"
   },
   "source": [
    "**To start, load the 'cv_hough_transform.png' image and binarize it, shown below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYdloe18wt2H"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "hough_image = cv2.imread('cv_hough_transform.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, hough_image = cv2.threshold(hough_image, 30, 255, cv2.THRESH_BINARY)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(hough_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucYRXmaNCWbZ"
   },
   "source": [
    "**Now we want to define some of the boundaries for the hough transform parameters space. Based on slide 46, set appropriate the theta_min, theta_max, and rho_max.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TbHppdcDC2e"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "x_max, y_max = hough_image.shape\n",
    "\n",
    "theta_max = \n",
    "theta_min = \n",
    "rho_max ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDE5QJ6bDLzT"
   },
   "source": [
    "**We then create the hough space, where we have 200 values for rho, and 300 valules for theta.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2a--7YtDVvd"
   },
   "outputs": [],
   "source": [
    "rho_dim = 200 \n",
    "theta_dim = 300\n",
    "hough_space = np.zeros((rho_dim,theta_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEXmPVYwDyOL"
   },
   "source": [
    "**We then loop through all of the edge pixels in the binarized edge image. For every theta from theta_min to theta_max, there is a rho that forms a line that goes through that pixel. Finish the expression for rho below by referencing slide 46. Then, compute the rho index to the hough space that we increment corresponding to that rho.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xB9OL6y7xvKS"
   },
   "outputs": [],
   "source": [
    "# Loop through every pixel\n",
    "for x in range(x_max):\n",
    "    for y in range(y_max):\n",
    "\n",
    "        # If that pixel not an edge, we move on to the next\n",
    "        if hough_image[x,y] == 255: continue\n",
    "\n",
    "        # Loop through all theta from theta_min to theta_max in small increments\n",
    "        for itheta in range(theta_dim):\n",
    "\n",
    "            # Get the theta that this itheta corresponds to\n",
    "            theta = theta_min + (1.0 * itheta * math.pi / theta_dim)\n",
    "\n",
    "            # Compute the rho that together with theta draws a line through [x, y]\n",
    "            rho = \n",
    "\n",
    "            # Scale the rho into somewhere between 0 to rho_max for indexing\n",
    "            irho = \n",
    "\n",
    "            # Increment that cell\n",
    "            hough_space[int(irho),itheta] = hough_space[int(irho),itheta] + 1\n",
    "\n",
    "plt.imshow(hough_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpDEV39JE8MW"
   },
   "source": [
    "**We see above the hough space with sinosoidal lines draw - which is what we expected! Also notice the five distinct points of overlap within the hough space - that's what we expect as well given that there are five edges in the image. Now that we have the hough space, we are interested in the maximum. This is done via non-maximum suppression, and is already done for you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oG4xHMeY0MsX"
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "image = hough_space\n",
    "\n",
    "image_max = ndimage.maximum_filter(hough_space, size=7, mode='constant')\n",
    "mask = (image == image_max)\n",
    "image *= mask\n",
    "\n",
    "# Remove the image borders\n",
    "image[:3] = 0\n",
    "image[-3:] = 0\n",
    "image[:, :3] = 0\n",
    "image[:, -3:] = 0\n",
    "\n",
    "# Find peaks above some threshold\n",
    "image_t = (image > 60) * 1\n",
    "\n",
    "# get coordinates of peaks\n",
    "f = np.transpose(image_t.nonzero())\n",
    "\n",
    "print(f)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQzK92fyFQuk"
   },
   "source": [
    "**The hotspots have now been isolated (they're just points so they may be difficult to see). The coordinates of each of those points are [rho, theta] pairs that represent a line in the real image space. Note that the [rho, theta] in f here are just indices into the range of rho's and theta's that we used for our hough space - we need to first get the real rho and theta parameters in order to draw the lines. Using these points in the hough space, draw in the detected lines onto the hough_image using cv2.line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9OfZus5y4cdF"
   },
   "outputs": [],
   "source": [
    "for parameters in f:\n",
    "  [i, j] = parameters\n",
    "  \n",
    "  # Compute the real rho and theta parameters given the index in the hough space\n",
    "  rho = \n",
    "  theta = \n",
    "\n",
    "  # Draw the lines here - you may need to compute x, y values for each line to be able to use cv2.line to draw them!\n",
    "\n",
    "\n",
    "plt.imshow(hough_image)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Week 3) Edge Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
